// Copyright 2013 Yangqing Jia

package caffe;

message BlobProto {
  optional int32 num = 1 [default = 0];
  optional int32 channels = 2 [default = 0];
  optional int32 height = 3 [default = 0];
  optional int32 width = 4 [default = 0];
  repeated float data = 5 [packed=true];
  repeated float diff = 6 [packed=true];
  repeated float second_diff = 7 [packed=true];
}

// The BlobProtoVector is simply a way to pass multiple blobproto instances
// around.
message BlobProtoVector {
  repeated BlobProto blobs = 1;
}

message Datum {
  optional int32 channels = 1;
  optional int32 height = 2;
  optional int32 width = 3;
  // the actual image data, in bytes
  optional bytes data = 4;
  optional int32 label = 5;
  // Optionally, the datum could also hold float data.
  repeated float float_data = 6;
  // For regression data set
  repeated float float_label = 7;
  // For learn to rank problems
  optional int32 group_id = 8;
}

message FillerParameter {
  // The filler type.
  optional string type = 1 [default = 'constant'];
  optional float value = 2 [default = 0]; // the value in constant filler
  optional float min = 3 [default = 0]; // the min value in uniform filler
  optional float max = 4 [default = 1]; // the max value in uniform filler
  optional float mean = 5 [default = 0]; // the mean value in gaussian filler
  optional float std = 6 [default = 1]; // the std value in gaussian filler
}

//For the node of decision tree
message TreeNodeProto {
	required uint32 feature_split = 1;
	required float value_split = 2;
	required bool leaf = 3;
	required uint32 nSamples = 4;
	required uint32 left_child = 5;
	required uint32 right_child = 6;
	required float ini_error = 7;
	required float best_error = 8;
	optional float pred = 9;
}

message TreeProto {
	repeated TreeNodeProto tree_nodes = 1;
}

message ForestProto {
	required float init_pred = 1;
	required uint32 dim = 2;
	required float learning_rate = 3;
	required uint32 max_depth = 4;
	required uint32 min_leaf_n = 5;
	repeated TreeProto trees = 6;
	required float rand_feat = 7;
	required float rand_samp = 8;
	required float min_obs = 9;
	required uint32 max_leaf_num = 10;
}

message LayerParameter {
  optional string name = 1; // the layer name
  optional string type = 2; // the string to specify the layer type

  // Parameters to specify layers with inner products.
  optional uint32 num_output = 3; // The number of outputs for the layer
  optional bool biasterm = 4 [default = true]; // whether to have bias terms
  optional FillerParameter weight_filler = 5; // The filler for the weight
  optional FillerParameter bias_filler = 6; // The filler for the bias

  optional uint32 pad = 7 [default = 0]; // The padding size
  optional uint32 kernelsize = 8; // The kernel size
  optional uint32 group = 9 [default = 1]; // The group size for group conv
  optional uint32 stride = 10 [default = 1]; // The stride
  enum PoolMethod {
    MAX = 0;
    AVE = 1;
    STOCHASTIC = 2;
  }
  optional PoolMethod pool = 11 [default = MAX]; // The pooling method
  optional float dropout_ratio = 12 [default = 0.5]; // dropout ratio

  optional uint32 local_size = 13 [default = 5]; // for local response norm
  optional float alpha = 14 [default = 1.]; // for local response norm
  optional float beta = 15 [default = 0.75]; // for local response norm

  // For data layers, specify the data source
  optional string source = 16;
  // For data pre-processing, we can do simple scaling and subtracting the
  // data mean, if provided. Note that the mean subtraction is always carried
  // out before scaling.
  optional float scale = 17 [ default = 1 ];
  optional string meanfile = 18;
  // For data layers, specify the batch size.
  optional uint32 batchsize = 19;
  // For data layers, specify if we would like to randomly crop an image.
  optional uint32 cropsize = 20 [default = 0];
  // For data layers, specify if we want to randomly mirror data.
  optional bool mirror = 21 [default = false];
  // For forest layers, the maximum depth for the trees.
  optional uint32 max_depth = 22 [default = 5];
  // For forest layers, the learning rate
  optional float forest_lr = 23 [default = 0.1];
  // For forest layers, the init std
  optional float forest_std = 24 [default = 1.0];
  // For forest layers, the minimum number of samples within a leaf node
  optional uint32 min_leaf_n = 25 [default = 1];
  // For multinomial layers, the power
  optional uint32 power = 26 [default = 1];
  // For data layers, the scope of jitter
  optional float jitter_rate = 27 [default = 0];
  // For data layers, if set to true, the database pointer will jump to a random
  // position before every iteration
  optional bool random_jump = 28 [default = true];
  // For rank net layers, the parameter to control the shape of sigmoid
  optional float delta = 29 [default = 1.0];
  // For lambda rank layers, top k of ndcg
  optional uint32 top_k = 30 [default = 0];
  // For forest layers, run n threads parallelly.
  optional uint32 n_threads = 31 [default = 1];
  // For data layers, whether to read data before each iteration
  optional bool batch_read = 32 [default = true];
  // For randomly feature selection of forest layers
  optional float rand_feat = 33 [default = 1.0];
  // For randomly sample selection of forest layers
  optional float rand_samp = 34 [default = 1.0];
  // For forest layers, minimum percentage of observation
  optional float min_obs = 35 [default = 0.0];
  // For forest layers, maximum number of leaves
  optional uint32 max_leaf_num = 36 [default = 9999];
  // For forest layers, wheter to use lazy predict
  optional bool lazy_pred = 37 [default = false];
  // For all layers, wheter to use 2nd order gradient
  optional bool cal_2nd_grad = 38 [default = false];
  
  // The blobs containing the numeric parameters of the layer
  repeated BlobProto blobs = 50;
  // The ratio that is multiplied on the global learning rate. If you want to set
  // the learning ratio for one blob, you need to set it for all blobs.
  repeated float blobs_lr = 51;
  // The weight decay that is multiplied on the global weight decay.
  repeated float weight_decay = 52;

  // The rand_skip variable is for the data layer to skip a few data points
  // to avoid all asynchronous sgd clients to start at the same point. The skip
  // point would be set as rand_skip * rand(0,1). Note that rand_skip should not
  // be larger than the number of keys in the leveldb.
  optional uint32 rand_skip = 53 [ default = 0 ];
  
  // The forests, for forest layer
  repeated ForestProto forests = 54;
}

message LayerConnection {
  optional LayerParameter layer = 1; // the layer parameter
  repeated string bottom = 2; // the name of the bottom blobs
  repeated string top = 3; // the name of the top blobs
}

message NetParameter {
  optional string name = 1; // consider giving the network a name
  repeated LayerConnection layers = 2; // a bunch of layers.
  // The input blobs to the network.
  repeated string input = 3;
  // The dim of the input blobs. For each input blob there should be four
  // values specifying the num, channels, height and width of the input blob.
  // Thus, there should be a total of (4 * #input) numbers.
  repeated int32 input_dim = 4;
  // Whether the network will force every layer to carry out backward operation.
  // If set False, then whether to carry out backward is determined
  // automatically according to the net structure and learning rates.
  optional bool force_backward = 5 [ default = false ];
}

message SolverParameter {
  optional string train_net = 1; // The proto file for the training net.
  optional string test_net = 2; // The proto file for the testing net.
  // The number of iterations for each testing phase.
  optional int32 test_iter = 3 [ default = 0 ];
  // The number of iterations between two testing phases.
  optional int32 test_interval = 4 [ default = 0 ];
  optional float base_lr = 5; // The base learning rate
  // the number of iterations between displaying info. If display = 0, no info
  // will be displayed.
  optional int32 display = 6;
  optional int32 max_iter = 7; // the maximum number of iterations
  optional string lr_policy = 8; // The learning rate decay policy.
  optional float gamma = 9; // The parameter to compute the learning rate.
  optional float power = 10; // The parameter to compute the learning rate.
  optional float momentum = 11; // The momentum value.
  optional float weight_decay = 12; // The weight decay.
  optional int32 stepsize = 13; // the stepsize for learning rate policy "step"
  optional int32 snapshot = 14 [default = 0]; // The snapshot interval
  optional string snapshot_prefix = 15; // The prefix for the snapshot.
  // whether to snapshot diff in the results or not. Snapshotting diff will help
  // debugging but the final protocol buffer size will be much larger.
  optional bool snapshot_diff = 16 [ default = false];
  // the mode solver will use: 0 for CPU and 1 for GPU. Use GPU in default.
  optional int32 solver_mode = 17 [default = 1];
  // the device_id will that be used in GPU mode. Use device_id=0 in default.
  optional int32 device_id = 18 [default = 0];
  optional bool cal_2nd_grad = 19 [default = false];
}

// A message that stores the solver snapshots
message SolverState {
  optional int32 iter = 1; // The current iteration
  optional string learned_net = 2; // The file that stores the learned net.
  repeated BlobProto history = 3; // The history for sgd solvers
}
